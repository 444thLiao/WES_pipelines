import sys
from os.path import dirname, join

sys.path.insert(0, dirname(dirname(__file__)))
from luigi_pipelines import config, valid_path
import pandas as pd
from tqdm import tqdm
import time, os
import pysamstats
import pysam

"""
confirmed at 2019.0620
Function to add extra column(Majority about mut_percent, ref_cov, mut_cov) from depth_info into csv_result file.
Type: Formatted-for function.
"""
# todo: instead of using pysamstats(too slow), use the covinfo generated by `cal_Cov_script_version.py`
tmp = ['deletions',
       'reads_pp',
       'reads_all',
       'matches_pp',
       'pos',
       'insertions_pp',
       'mismatches',
       'C_pp',
       'matches',
       'N_pp',
       'ref',
       'T_pp',
       'A',
       'C',
       'G',
       'deletions_pp',
       'N',
       'mismatches_pp',
       'T',
       'A_pp',
       'chrom',
       'insertions',
       'G_pp']

added_col = ['N_mut_cov',
             'N_mut_per',
             'N_ref_cov',
             'T_mut_cov',
             'T_mut_per',
             'T_ref_cov']


def parse_bam(bam, Chr, Pos, End, Ref, Alt, REF, ):
    # exec_pysamstats = '/home/liaoth/tools/pysamstats_venv/bin/pysamstats'
    #
    # t_result = os.popen(
    #     '{exe} --fasta {fa} --type variation {t_f} -c {chr} -s {start} -e {end} -u'
    #         .format(exe=exec_pysamstats, fa=fasta, t_f=bam_path, chr=Chr, start=Pos, end=End + 1)).read()
    result = pysamstats.stat_variation(bam,
                                       REF,
                                       chrom=Chr,
                                       start=Pos,
                                       end=End + 1,
                                       truncate=True,
                                       one_based=True)
    result_dict = {}
    for idx, record in enumerate(result):
        result_dict[idx] = record
    data_df = pd.DataFrame.from_dict(result_dict, orient='index')

    if data_df.shape[0] == 0:
        data_df = data_df.append(pd.DataFrame(columns=tmp))
        data_df.loc[0, :] = 0

    if Ref in ['A', 'C', 'G', 'T'] and Alt in ['A', 'C', 'G', 'T']:
        ref_cov, mut_cov, cov = data_df.loc[0,
                                            [Ref + '_pp',
                                             Alt + '_pp',
                                             'reads_pp']]

        if cov != 0:
            mut_per = mut_cov / float(cov)
        else:
            mut_per = 0

    else:
        if data_df.sum()['reads_pp'] > 0 and len(data_df) > 0:
            if Ref == '-' or len(Alt) > len(Ref):
                # insertions
                mut_per = data_df.sum()['insertions_pp'] / float(data_df.sum()['reads_pp'])
                ref_cov = data_df.sum()['matches_pp'] / float(len(data_df))
                mut_cov = data_df.sum()['insertions_pp'] / float(len(data_df))
            elif Alt == '-' or len(Ref) > len(Alt):
                # deletions
                mut_per = data_df.sum(0)['deletions_pp'] / float(data_df.sum()['reads_pp'])
                ref_cov = data_df.sum(0)['matches_pp'] / float(len(data_df))
                mut_cov = data_df.sum(0)['deletions_pp'] / float(len(data_df))
            else:
                return ['Wrong pos'] * 3
        else:
            return ['Off target'] * 3
    return mut_cov, mut_per, ref_cov


def add_per_info(result_csvs, output_csvs, tumor_bam, normal_bam, bed_file):
    '''
    :param result_csv:
    :param output_csv:
    :param tumor_bam:
    :param normal_bam:
    :return:
    '''
    fasta = config.REF_file_path
    print('{:#^40}'.format('Start Whole project...'))
    t1 = time.time()
    bed_df = pd.read_csv(bed_file, sep='\t', header=None)
    range_list = []
    for _idx in tqdm(range(bed_df.shape[0])):
        range_list += ['chr' + str(_i)
                       for _i in range(bed_df.iloc[_idx, 1],
                                       bed_df.iloc[_idx, 2])]
    tb = pysam.AlignmentFile(tumor_bam)
    nb = pysam.AlignmentFile(normal_bam)
    ref_ = pysam.FastaFile(fasta)

    for result_csv, output_csv in zip(result_csvs,
                                      output_csvs):
        result_csv = os.path.realpath(result_csv)
        output_csv = os.path.realpath(output_csv)
        # ~ in path is missing location.It will raise error, so need to expand it.
        ori_csv = pd.read_csv(result_csv, index_col=None)
        t2 = time.time()
        print('{:#^40}'.format('Loaded/Inited all required file...... Using %d ' % (t2 - t1)))
        print('{:#^40}'.format('Star Iteration.......'))

        for _ in added_col:
            # init a col or add a new column.
            ori_csv.loc[:, _] = 0

        for _index, row in tqdm(ori_csv.iterrows(),
                                total=ori_csv.shape[0]):
            Ref = row['Ref']
            Alt = row['Alt']
            Chr = row['Chr']
            Pos = int(row['Start'])
            End = int(row['End'])
            if not set(['chr' + str(_i)
                        for _i in range(Pos,
                                        End + 1)]).intersection(range_list):
                # if this pos at the range of WES bed indicated.
                # if it is a deletion or intersection, partially intersected also is ok.
                ori_csv.loc[_index, added_col] = 'Off target'
                continue
            if tumor_bam:
                mut_cov, mut_per, ref_cov = parse_bam(tb, Chr, Pos, End, Ref, Alt, ref_)
                ori_csv.loc[_index, added_col[-3:]] = mut_cov, mut_per, ref_cov
            if normal_bam:
                mut_cov, mut_per, ref_cov = parse_bam(nb, Chr, Pos, End, Ref, Alt, ref_)
                ori_csv.loc[_index, added_col[:3]] = mut_cov, mut_per, ref_cov
        print('{:#^40}'.format('Almost Completing. Iteration used %d.' % (time.time() - t2)))
        print('{:#^40}'.format('filtering all unconvinced snp/indel.'))

        # a_num.T_mut_per = a_num.T_mut_per.astype(float)
        # a_num.N_mut_per = a_num.N_mut_per.astype(float)
        # a_num = a_num[a_num.T_mut_per >= a_num.N_mut_per]
        # a_num = a_num[a_num.T_mut_per != 0]
        valid_path(output_csv, check_ofile=1)
        with open(output_csv, 'w') as f1:
            ori_csv.to_csv(f1, index=False)


if __name__ == '__main__':
    import argparse

    parser = argparse.ArgumentParser()
    parser.add_argument('-i', '--input', dest='input', type=str, required=True, nargs='+',
                        help="input csv file. could be multiple, but must have the same number of files to output file.")
    parser.add_argument('-o', '--output', dest='output', type=str, required=True, nargs='+', help="output csv file")
    parser.add_argument('-tb', dest='tumor_bam', type=str, help='path to specify the tumor sample bam file, normally suffix is recal_reads.bam')
    parser.add_argument('-nb', dest='normal_bam', type=str, help='path to specify the normal sample bam file, normally suffix is recal_reads.bam')
    parser.add_argument('-b', dest='bed_file', type=str, help='path to specify the bed file',
                        default=join(dirname(dirname(__file__)),
                                     "db",
                                     "Sureselect_V6_COSMIC_formal.bed"))

    args = parser.parse_args()
    input = args.input
    output = args.output
    tb = args.tumor_bam
    nb = args.normal_bam
    bed_file_ = args.bed_file
    input = input
    output = output
    add_per_info(input, output, tb, nb, bed_file_)
